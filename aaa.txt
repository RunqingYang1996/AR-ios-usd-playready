#!/usr/bin/env python3
# -*- coding: utf-8 -*-

# stylegan2_from_pdf_macfast.py
# - W-only：Mapping 只输出 256 维 w
# - PathLengthPenalty 对参与生成的 w 求梯度（修复未参与图报错）
# - Mac 优化：MPS + FP16 autocast、channels_last、DataLoader 调参
# - 训练中降低 WGAN-GP 频率/抽样子集以省时
# - 每 50 epoch 出图 + 存档，支持 --resume

import os
from math import sqrt
from dataclasses import dataclass
from typing import Optional

import numpy as np
import torch
from torch import nn, optim
import torch.nn.functional as F
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
from torchvision.transforms import InterpolationMode as Inter
from torchvision.utils import save_image
from tqdm import tqdm

# -----------------------------
# Hyperparams
# -----------------------------
@dataclass
class HParams:
    dataset: str = "./DATASET"
    device: str = "mps" if torch.backends.mps.is_available() else "cpu"
    epochs: int = 300
    lr: float = 1e-3
    batch_size: int = 32
    log_resolution: int = 7         # 2**7 = 128
    z_dim: int = 256
    w_dim: int = 256
    lambda_gp: float = 10.0         # WGAN-GP
    plp_beta: float = 0.99          # PathLengthPenalty EMA beta

# -----------------------------
# Equalized layers & helpers
# -----------------------------
class EqualizedWeight(nn.Module):
    def __init__(self, shape):
        super().__init__()
        self.c = 1 / sqrt(np.prod(shape[1:]))
        self.weight = nn.Parameter(torch.randn(shape))

    def forward(self):
        return self.weight * self.c

class EqualizedLinear(nn.Module):
    def __init__(self, in_features, out_features, bias=0.0):
        super().__init__()
        self.weight = EqualizedWeight([out_features, in_features])
        self.bias = nn.Parameter(torch.ones(out_features) * bias)

    def forward(self, x: torch.Tensor):
        return F.linear(x, self.weight(), bias=self.bias)

class EqualizedConv2d(nn.Module):
    def __init__(self, in_features, out_features, kernel_size, padding=0):
        super().__init__()
        self.padding = padding
        self.weight = EqualizedWeight([out_features, in_features, kernel_size, kernel_size])
        self.bias = nn.Parameter(torch.ones(out_features))

    def forward(self, x: torch.Tensor):
        return F.conv2d(x, self.weight(), bias=self.bias, padding=self.padding)

class Conv2dWeightModulate(nn.Module):
    def __init__(self, in_features, out_features, kernel_size, demodulate=True, eps=1e-8):
        super().__init__()
        self.out_features = out_features
        self.demodulate = demodulate
        self.padding = (kernel_size - 1) // 2
        self.weight = EqualizedWeight([out_features, in_features, kernel_size, kernel_size])
        self.eps = eps

    def forward(self, x, s):
        # x: [B,Cin,H,W], s: [B,Cin]
        b, _, h, w = x.shape
        s = s[:, None, :, None, None]                     # [B,1,Cin,1,1]
        weights = self.weight()[None, :, :, :, :]         # [1,Cout,Cin,k,k]
        weights = weights * s                             # [B,Cout,Cin,k,k]

        if self.demodulate:
            sigma_inv = torch.rsqrt((weights ** 2).sum(dim=(2, 3, 4), keepdim=True) + self.eps)
            weights = weights * sigma_inv

        x = x.reshape(1, -1, h, w)                        # [1,B*Cin,H,W]
        _, _, *ws = weights.shape
        weights = weights.reshape(b * self.out_features, *ws)  # [B*Cout,Cin,k,k]

        x = F.conv2d(x, weights, padding=self.padding, groups=b)
        return x.reshape(-1, self.out_features, h, w)

# -----------------------------
# Mapping Network (W-only, 256)
# -----------------------------
class MappingNetwork(nn.Module):
    # 8 层：第一层 z→w，其余 7 层 w→w；输入先做 PixelNorm；最后一层不加 ReLU
    def __init__(self, z_dim, w_dim):
        super().__init__()
        layers = []
        layers.append(EqualizedLinear(z_dim, w_dim)); layers.append(nn.ReLU())
        for _ in range(6):
            layers.append(EqualizedLinear(w_dim, w_dim)); layers.append(nn.ReLU())
        layers.append(EqualizedLinear(w_dim, w_dim))
        self.mapping = nn.Sequential(*layers)

    def forward(self, x):
        x = x / torch.sqrt(torch.mean(x ** 2, dim=1, keepdim=True) + 1e-8)  # PixelNorm
        return self.mapping(x)  # [B, w_dim]

# -----------------------------
# Generator
# -----------------------------
class StyleBlock(nn.Module):
    def __init__(self, W_DIM, in_features, out_features):
        super().__init__()
        self.to_style = EqualizedLinear(W_DIM, in_features, bias=1.0)
        self.conv = Conv2dWeightModulate(in_features, out_features, kernel_size=3)
        self.scale_noise = nn.Parameter(torch.zeros(1))
        self.bias = nn.Parameter(torch.zeros(out_features))
        self.activation = nn.LeakyReLU(0.2, True)

    def forward(self, x, w, noise):
        s = self.to_style(w)
        x = self.conv(x, s)
        if noise is not None:
            x = x + self.scale_noise[None, :, None, None] * noise
        return self.activation(x + self.bias[None, :, None, None])

class ToRGB(nn.Module):
    def __init__(self, W_DIM, features):
        super().__init__()
        self.to_style = EqualizedLinear(W_DIM, features, bias=1.0)
        self.conv = Conv2dWeightModulate(features, 3, kernel_size=1, demodulate=False)
        self.bias = nn.Parameter(torch.zeros(3))
        # 原论文 ToRGB 通常不再激活，但保留你实现的 LeakyReLU 也可
        self.activation = nn.LeakyReLU(0.2, True)

    def forward(self, x, w):
        style = self.to_style(w)
        x = self.conv(x, style)
        return self.activation(x + self.bias[None, :, None, None])

class GeneratorBlock(nn.Module):
    def __init__(self, W_DIM, in_features, out_features):
        super().__init__()
        self.style_block1 = StyleBlock(W_DIM, in_features, out_features)
        self.style_block2 = StyleBlock(W_DIM, out_features, out_features)
        self.to_rgb = ToRGB(W_DIM, out_features)

    def forward(self, x, w, noise):
        x = self.style_block1(x, w, noise[0])
        x = self.style_block2(x, w, noise[1])
        rgb = self.to_rgb(x, w)
        return x, rgb

class Generator(nn.Module):
    def __init__(self, log_resolution, W_DIM, n_features=32, max_features=256):
        super().__init__()
        features = [min(max_features, n_features * (2 ** i)) for i in range(log_resolution - 2, -1, -1)]
        self.n_blocks = len(features)

        self.initial_constant = nn.Parameter(torch.randn((1, features[0], 4, 4)))
        self.style_block = StyleBlock(W_DIM, features[0], features[0])
        self.to_rgb = ToRGB(W_DIM, features[0])

        blocks = [GeneratorBlock(W_DIM, features[i - 1], features[i]) for i in range(1, self.n_blocks)]
        self.blocks = nn.ModuleList(blocks)

    def forward(self, w, input_noise):
        """
        w: [B, W_DIM] 或 [n_blocks, B, W_DIM]
        input_noise: list[(n1, n2)] per block; i==0: n1=None
        """
        if w.dim() == 2:  # [B, W_DIM] -> 广播为每个 block 共用
            w = w[None, :, :].expand(self.n_blocks, -1, -1)

        batch_size = w.shape[1]
        x = self.initial_constant.expand(batch_size, -1, -1, -1).contiguous(memory_format=torch.channels_last)
        x = self.style_block(x, w[0], input_noise[0][1])
        rgb = self.to_rgb(x, w[0])

        for i in range(1, self.n_blocks):
            x = F.interpolate(x, scale_factor=2, mode="bilinear", align_corners=False)
            x = x.contiguous(memory_format=torch.channels_last)
            x, rgb_new = self.blocks[i - 1](x, w[i], input_noise[i])
            rgb = F.interpolate(rgb, scale_factor=2, mode="bilinear", align_corners=False)
            rgb = rgb + rgb_new

        return torch.tanh(rgb)

# -----------------------------
# Discriminator
# -----------------------------
class DiscriminatorBlock(nn.Module):
    def __init__(self, in_features, out_features):
        super().__init__()
        self.residual = nn.Sequential(
            nn.AvgPool2d(kernel_size=2, stride=2),
            EqualizedConv2d(in_features, out_features, kernel_size=1),
        )
        self.block = nn.Sequential(
            EqualizedConv2d(in_features, in_features, kernel_size=3, padding=1),
            nn.LeakyReLU(0.2, True),
            EqualizedConv2d(in_features, out_features, kernel_size=3, padding=1),
            nn.LeakyReLU(0.2, True),
        )
        self.down_sample = nn.AvgPool2d(kernel_size=2, stride=2)
        self.scale = 1 / sqrt(2)

    def forward(self, x):
        residual = self.residual(x)
        x = self.block(x)
        x = self.down_sample(x)
        return (x + residual) * self.scale

class Discriminator(nn.Module):
    def __init__(self, log_resolution, n_features=64, max_features=256):
        super().__init__()
        features = [min(max_features, n_features * (2 ** i)) for i in range(log_resolution - 1)]

        self.from_rgb = nn.Sequential(
            EqualizedConv2d(3, n_features, 1),
            nn.LeakyReLU(0.2, True),
        )
        n_blocks = len(features) - 1
        blocks = [DiscriminatorBlock(features[i], features[i + 1]) for i in range(n_blocks)]
        self.blocks = nn.Sequential(*blocks)

        final_features = features[-1] + 1  # +1 for minibatch std channel
        self.conv = EqualizedConv2d(final_features, final_features, 3)
        self.final = EqualizedLinear(2 * 2 * final_features, 1)

    def minibatch_std(self, x):
        batch_statistics = (torch.std(x, dim=0).mean().repeat(x.shape[0], 1, x.shape[2], x.shape[3]))
        return torch.cat([x, batch_statistics], dim=1)

    def forward(self, x):
        x = self.from_rgb(x)
        x = self.blocks(x)
        x = self.minibatch_std(x)
        x = self.conv(x)
        x = x.reshape(x.shape[0], -1)
        return self.final(x)

# -----------------------------
# Utils
# -----------------------------
def gradient_penalty(critic, real, fake, device="cpu"):
    B, C, H, W = real.shape
    beta = torch.rand((B, 1, 1, 1), device=device).repeat(1, C, H, W)
    interpolated_images = real * beta + fake.detach() * (1 - beta)
    interpolated_images.requires_grad_(True)

    mixed_scores = critic(interpolated_images)
    gradient = torch.autograd.grad(
        inputs=interpolated_images,
        outputs=mixed_scores,
        grad_outputs=torch.ones_like(mixed_scores),
        create_graph=True,
        retain_graph=True,
    )[0]
    gradient = gradient.view(gradient.shape[0], -1)
    gradient_norm = gradient.norm(2, dim=1)
    return torch.mean((gradient_norm - 1) ** 2)

class PathLengthPenalty(nn.Module):
    # 兼容 w=[B,W] 或 [n_blocks,B,W]
    def __init__(self, beta):
        super().__init__()
        self.beta = beta
        self.steps = nn.Parameter(torch.tensor(0.), requires_grad=False)
        self.exp_sum_a = nn.Parameter(torch.tensor(0.), requires_grad=False)

    def forward(self, w, x):
        """
        w: [B, W_DIM] 或 [n_blocks, B, W_DIM]；需与 x 共享前向图
        x: [B, 3, H, W]
        """
        device = x.device
        image_size = x.shape[2] * x.shape[3]
        y = torch.randn_like(x)

        output = (x * y).sum() / sqrt(image_size)
        grads = torch.autograd.grad(
            outputs=output,
            inputs=w,
            grad_outputs=torch.ones((), device=device),
            create_graph=True,
            retain_graph=True,
            allow_unused=True,
        )[0]

        if grads is None:
            return x.new_tensor(0.)

        if grads.dim() == 3:
            norm = (grads.pow(2).sum(dim=2).mean(dim=0)).sqrt()  # [B]
        elif grads.dim() == 2:
            norm = (grads.pow(2).sum(dim=1)).sqrt()              # [B]
        else:
            raise RuntimeError(f"Unexpected grads dim: {grads.dim()}")

        if self.steps > 0:
            a = self.exp_sum_a / (1 - self.beta ** self.steps)
            loss = torch.mean((norm - a) ** 2)
        else:
            loss = norm.new_tensor(0)

        mean = norm.mean().detach()
        self.exp_sum_a.mul_(self.beta).add_(mean, alpha=1 - self.beta)
        self.steps.add_(1.)
        return loss

# -----------------------------
# Data loader (Mac/MPS 优化)
# -----------------------------
def get_loader(hp: HParams):
    transform = transforms.Compose([
        transforms.Resize((2 ** hp.log_resolution, 2 ** hp.log_resolution), interpolation=Inter.BILINEAR),
        transforms.ToTensor(),
        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),
    ])
    dataset = datasets.ImageFolder(root=hp.dataset, transform=transform)
    loader = DataLoader(
        dataset,
        batch_size=hp.batch_size,
        shuffle=True,
        num_workers=max(2, os.cpu_count() - 1),
        pin_memory=False,             # CUDA 专用，MPS/CPU 关闭更快
        persistent_workers=True,
        prefetch_factor=4,
        drop_last=True,               # 保持 batch 尺寸一致更稳
    )
    return loader

# -----------------------------
# Sampling helpers (W-only)
# -----------------------------
def get_w(batch_size, hp: HParams, mapping_network: MappingNetwork):
    z = torch.randn(batch_size, hp.z_dim, device=hp.device)
    w = mapping_network(z)  # [B, W_DIM]
    return w

def get_noise(batch_size, hp: HParams):
    noise = []
    resolution = 4
    for i in range(hp.log_resolution):
        n1 = None if i == 0 else torch.randn(batch_size, 1, resolution, resolution, device=hp.device)
        n2 = torch.randn(batch_size, 1, resolution, resolution, device=hp.device)
        noise.append((n1, n2))
        resolution *= 2
    return noise

@torch.no_grad()
def generate_examples(gen: Generator, mapping_network: MappingNetwork, hp: HParams, epoch: int, n: int = 50):
    gen.eval()
    out_dir = f"saved_examples/epoch{epoch}"
    os.makedirs(out_dir, exist_ok=True)
    for i in range(n):
        w = get_w(1, hp, mapping_network)  # [1,256]
        noise = get_noise(1, hp)
        img = gen(w, noise).detach().cpu()
        save_image(img * 0.5 + 0.5, os.path.join(out_dir, f"img_{i:03d}.png"))
    gen.train()

# -----------------------------
# Checkpoint utils
# -----------------------------
def save_checkpoint(epoch: int,
                    gen: Generator,
                    critic: Discriminator,
                    mapping: MappingNetwork,
                    opt_g: optim.Optimizer,
                    opt_c: optim.Optimizer,
                    opt_m: optim.Optimizer,
                    plp: PathLengthPenalty,
                    hp: HParams,
                    tag: Optional[str] = None):
    os.makedirs("checkpoints", exist_ok=True)
    name = f"epoch_{epoch:04d}.pt" if tag is None else f"{tag}.pt"
    path = os.path.join("checkpoints", name)
    torch.save({
        "epoch": epoch,
        "hp": hp.__dict__,
        "gen": gen.state_dict(),
        "critic": critic.state_dict(),
        "mapping": mapping.state_dict(),
        "opt_g": opt_g.state_dict(),
        "opt_c": opt_c.state_dict(),
        "opt_m": opt_m.state_dict(),
        "plp": plp.state_dict(),
    }, path)
    return path

def load_checkpoint(path: str,
                    gen: Generator,
                    critic: Discriminator,
                    mapping: MappingNetwork,
                    opt_g: optim.Optimizer,
                    opt_c: optim.Optimizer,
                    opt_m: optim.Optimizer,
                    plp: PathLengthPenalty):
    ckpt = torch.load(path, map_location="cpu")
    gen.load_state_dict(ckpt["gen"])
    critic.load_state_dict(ckpt["critic"])
    mapping.load_state_dict(ckpt["mapping"])
    if "opt_g" in ckpt: opt_g.load_state_dict(ckpt["opt_g"])
    if "opt_c" in ckpt: opt_c.load_state_dict(ckpt["opt_c"])
    if "opt_m" in ckpt: opt_m.load_state_dict(ckpt["opt_m"])
    if "plp" in ckpt: plp.load_state_dict(ckpt["plp"])
    start_epoch = ckpt.get("epoch", -1) + 1
    return start_epoch, ckpt.get("hp", None)

# -----------------------------
# Train loop (MacFast)
# -----------------------------
def train_fn(
    critic: Discriminator,
    gen: Generator,
    path_length_penalty: PathLengthPenalty,
    loader: DataLoader,
    opt_critic,
    opt_gen,
    opt_mapping_network,
    mapping_network: MappingNetwork,
    hp: HParams,
):
    loop = tqdm(loader, leave=True)

    use_mps = (hp.device == "mps")
    amp_kwargs = dict(device_type='mps', dtype=torch.float16, enabled=True) if use_mps else dict(device_type='cpu', enabled=False)

    # —— WGAN-GP 降频与子集抽样（可调）——
    gp_every = 4        # 每 4 iter 计算一次 GP
    gp_subset = 0.5     # 用 50% batch 做 GP，并除以该比例恢复期望

    for batch_idx, (real, _) in enumerate(loop):
        real = real.to(hp.device).to(memory_format=torch.channels_last)
        cur_batch_size = real.shape[0]

        w_single = get_w(cur_batch_size, hp, mapping_network)   # [B,256]
        noise = get_noise(cur_batch_size, hp)

        # ----- Critic -----
        with torch.amp.autocast(**amp_kwargs):
            fake = gen(w_single, noise)
            critic_fake = critic(fake.detach())
            critic_real  = critic(real)

            do_gp = (batch_idx % gp_every == 0)
            if do_gp:
                if gp_subset < 1.0 and cur_batch_size > 1:
                    k = max(1, int(cur_batch_size * gp_subset))
                    idx = torch.randint(0, cur_batch_size, (k,), device=real.device)
                    real_gp = real.index_select(0, idx)
                    fake_gp = fake.detach().index_select(0, idx)
                else:
                    real_gp = real
                    fake_gp = fake.detach()

                gp = gradient_penalty(critic, real_gp, fake_gp, device=hp.device)
                if gp_subset < 1.0:
                    gp = gp / gp_subset
            else:
                gp = torch.zeros((), device=real.device)

            loss_critic = (-(torch.mean(critic_real) - torch.mean(critic_fake))
                           + hp.lambda_gp * gp
                           + (0.001 * torch.mean(critic_real ** 2)))  # drift

        critic.zero_grad(set_to_none=True)
        loss_critic.backward()
        opt_critic.step()

        # ----- Generator & Mapping -----
        with torch.amp.autocast(**amp_kwargs):
            gen_fake = critic(fake)
            loss_gen = -torch.mean(gen_fake)

            if batch_idx % 16 == 0:
                plp = path_length_penalty(w_single, fake)  # 对参与生成的 w 求 PLP
                if not torch.isnan(plp):
                    loss_gen = loss_gen + plp

        mapping_network.zero_grad(set_to_none=True)
        gen.zero_grad(set_to_none=True)
        loss_gen.backward()
        opt_gen.step()
        opt_mapping_network.step()

        loop.set_postfix(gp=float(gp.item()), loss_critic=float(loss_critic.item()))

# -----------------------------
# Main
# -----------------------------
def main():
    import argparse
    ap = argparse.ArgumentParser()
    ap.add_argument("--dataset", type=str, required=True)
    ap.add_argument("--epochs", type=int, default=300)
    ap.add_argument("--lr", type=float, default=1e-3)
    ap.add_argument("--batch_size", type=int, default=32)
    ap.add_argument("--log_resolution", type=int, default=7)
    ap.add_argument("--z_dim", type=int, default=256)
    ap.add_argument("--w_dim", type=int, default=256)
    ap.add_argument("--lambda_gp", type=float, default=10.0)
    ap.add_argument("--resume", type=str, default="")
    args = ap.parse_args()

    # 设备优先选择 MPS
    hp = HParams(
        dataset=args.dataset,
        epochs=args.epochs,
        lr=args.lr,
        batch_size=args.batch_size,
        log_resolution=args.log_resolution,
        z_dim=args.z_dim,
        w_dim=args.w_dim,
        lambda_gp=args.lambda_gp,
        device="mps" if torch.backends.mps.is_available() else "cpu",
    )
    device = torch.device(hp.device)
    torch.set_float32_matmul_precision("high")
    torch.set_num_threads(max(1, os.cpu_count() - 1))

    loader = get_loader(hp)

    gen = Generator(hp.log_resolution, hp.w_dim).to(device, memory_format=torch.channels_last)
    critic = Discriminator(hp.log_resolution).to(device, memory_format=torch.channels_last)
    mapping_network = MappingNetwork(hp.z_dim, hp.w_dim).to(device)
    path_length_penalty = PathLengthPenalty(hp.plp_beta).to(device)

    opt_gen = optim.Adam(gen.parameters(), lr=hp.lr, betas=(0.0, 0.99))
    opt_critic = optim.Adam(critic.parameters(), lr=hp.lr, betas=(0.0, 0.99))
    opt_mapping_network = optim.Adam(mapping_network.parameters(), lr=hp.lr, betas=(0.0, 0.99))

    gen.train(); critic.train(); mapping_network.train()

    # ---- Resume ----
    start_epoch = 0
    if args.resume and os.path.isfile(args.resume):
        start_epoch, hp_from_ckpt = load_checkpoint(
            args.resume, gen, critic, mapping_network,
            opt_gen, opt_critic, opt_mapping_network, path_length_penalty
        )
        if hp_from_ckpt is not None:
            ck = hp_from_ckpt
            need_rebuild = (ck.get("log_resolution", hp.log_resolution) != hp.log_resolution) or \
                           (ck.get("w_dim", hp.w_dim) != hp.w_dim) or \
                           (ck.get("z_dim", hp.z_dim) != hp.z_dim)
            if need_rebuild:
                print("Rebuilding nets to match checkpoint hyperparams...")
                hp.log_resolution = ck.get("log_resolution", hp.log_resolution)
                hp.w_dim = ck.get("w_dim", hp.w_dim)
                hp.z_dim = ck.get("z_dim", hp.z_dim)
                gen = Generator(hp.log_resolution, hp.w_dim).to(device, memory_format=torch.channels_last)
                critic = Discriminator(hp.log_resolution).to(device, memory_format=torch.channels_last)
                mapping_network = MappingNetwork(hp.z_dim, hp.w_dim).to(device)
                load_checkpoint(args.resume, gen, critic, mapping_network,
                                opt_gen, opt_critic, opt_mapping_network, path_length_penalty)

        print(f"Resumed from {args.resume}, start_epoch={start_epoch}")

    # ---- Training ----
    for epoch in range(start_epoch, hp.epochs):
        train_fn(
            critic=critic,
            gen=gen,
            path_length_penalty=path_length_penalty,
            loader=loader,
            opt_critic=opt_critic,
            opt_gen=opt_gen,
            opt_mapping_network=opt_mapping_network,
            mapping_network=mapping_network,
            hp=hp,
        )

        if (epoch + 1) % 50 == 0:
            generate_examples(gen, mapping_network, hp, epoch + 1, n=50)
            ck = save_checkpoint(epoch + 1, gen, critic, mapping_network,
                                 opt_gen, opt_critic, opt_mapping_network,
                                 path_length_penalty, hp, tag=f"epoch_{epoch+1:04d}")
            print(f"Saved checkpoint: {ck}")

        save_checkpoint(epoch + 1, gen, critic, mapping_network,
                        opt_gen, opt_critic, opt_mapping_network,
                        path_length_penalty, hp, tag="latest")

if __name__ == "__main__":
    main()
python stylegan2_from_pdf_macfast.py \
  --dataset /path/to/ImageFolder \
  --epochs 200 \
  --batch_size 8 \
  --log_resolution 6 \
  --z_dim 256 \
  --w_dim 256 \
  --lr 1e-3
